{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwihIpOuWf8L",
        "outputId": "4ca53ca3-41d8-4ecc-c72e-02df38313c42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Random Forest...\n",
            "Random Forest RMSE on Test Data: 68.57110944031409\n",
            "Training Linear Regression...\n",
            "Linear Regression RMSE on Test Data: 56.48873255260203\n",
            "Training Decision Tree...\n",
            "Decision Tree RMSE on Test Data: 71.54451380364534\n",
            "Training SVM...\n",
            "SVM RMSE on Test Data: 70.57112988304745\n",
            "Best model: Linear Regression with RMSE: 56.48873255260203\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error\n",
        "# Import regression models instead of classification models\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import math\n",
        "import pickle\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "file_name = '/content/ML Project Data fixed.xlsx'  # Ensure this file is in the same directory as your script\n",
        "df = pd.read_excel(file_name)\n",
        "\n",
        "# Data Preprocessing\n",
        "# Encode categorical variables\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# no label encoding needed\n",
        "df['Label'] = df['Label']\n",
        "\n",
        "# Apply one-hot encoding to the feature columns (Token_0 to Token_9)\n",
        "df_encoded = pd.get_dummies(df, columns=[f'Token_{i}' for i in range(10)], drop_first=True)\n",
        "\n",
        "# Splitting the dataset into training and test sets\n",
        "X = df_encoded.drop('Label', axis=1)\n",
        "y = df_encoded['Label']\n",
        "\n",
        "# Split data into train and test sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardizing the data (for certain models like SVM)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Machine Learning Models\n",
        "models = {\n",
        "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
        "    \"Linear Regression\": LinearRegression(),\n",
        "    \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
        "    \"SVM\": SVR()\n",
        "}\n",
        "\n",
        "# Training and evaluating the models\n",
        "best_model = None\n",
        "best_rmse = float('inf')\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"Training {model_name}...\")\n",
        "\n",
        "    # Use scaled data for SVM, for others, use non-scaled data\n",
        "    if model_name == \"SVM\":\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        y_test_pred = model.predict(X_test_scaled)\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate RMSE for the test dataset\n",
        "    rmse_test = math.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "\n",
        "    # Save the best model based on RMSE for the test dataset\n",
        "    if rmse_test < best_rmse:\n",
        "        best_rmse = rmse_test\n",
        "        best_model = model\n",
        "        best_model_name = model_name\n",
        "\n",
        "    print(f\"{model_name} RMSE on Test Data: {rmse_test}\")\n",
        "\n",
        "# Save the best model\n",
        "with open('best_model.pkl', 'wb') as f:\n",
        "    pickle.dump(best_model, f)\n",
        "\n",
        "# Save the feature columns after preprocessing\n",
        "with open('feature_columns.pkl', 'wb') as f:\n",
        "    pickle.dump(X_train.columns.tolist(), f)\n",
        "\n",
        "print(f\"Best model: {best_model_name} with RMSE: {best_rmse}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import sys\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "# Force install scikit-learn if not found\n",
        "try:\n",
        "    import sklearn\n",
        "except ModuleNotFoundError:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"scikit-learn\"])\n",
        "    import sklearn  # Import again after installation\n",
        "\n",
        "\n",
        "# Load the pre-trained model\n",
        "with open('best_model.pkl', 'rb') as model_file:\n",
        "    model = pickle.load(model_file)\n",
        "\n",
        "# Load the feature columns used during training\n",
        "with open('feature_columns.pkl', 'rb') as f:\n",
        "    required_columns = pickle.load(f)\n",
        "\n",
        "# Title of the app\n",
        "st.title(\"GUI for Pharmaceutical Removal via Biochar Adsorption\")\n",
        "\n",
        "# Sidebar inputs for user preferences\n",
        "st.sidebar.header(\"Inputs\")\n",
        "\n",
        "TP = st.sidebar.selectbox(\n",
        "    \"Pharmaceutical Type\",\n",
        "    [\n",
        "        'Benzocain', 'Ciprofloxacin', 'Citalopram', 'Diclofenac',\n",
        "        'Dimetridazole', 'Floxentine', 'ibuprofen', 'Metronidazole',\n",
        "        'Nitroimidazole', 'Norfloxacin', 'Oxytetracycline',\n",
        "        'Salicylic acid', 'Sulfadiazine', 'Sulfamethazine',\n",
        "        'Sulfamethoxazole', 'Tetracycline', 'Triclosan'\n",
        "    ]\n",
        ")\n",
        "temp = st.sidebar.slider(\"Temperature\", 300, 950, 300, 1)\n",
        "time = st.sidebar.slider(\"Time (min)\", 0.1, 480.0, 0.1, 0.1)\n",
        "PS = st.sidebar.slider(\"PS\", 1.32, 213.29, 1.32, 0.01)\n",
        "BET = st.sidebar.slider(\"BET\", 0.48, 1838.86, 0.48, 0.01)\n",
        "PV = st.sidebar.slider(\"PV\", 0.001, 1.03, 0.001, 0.001)\n",
        "carbon = st.sidebar.slider(\"Carbon (%)\", 9.46, 89.57, 9.46, 0.01)\n",
        "hydrogen = st.sidebar.slider(\"Hydrogen (%)\", 0.0, 10.30, 0.0, 0.01)\n",
        "nitrogen = st.sidebar.slider(\"Nitrogen (%)\", 0.0, 14.15, 0.0, 0.01)\n",
        "oxygen = st.sidebar.slider(\"Oxygen (%)\", 0.67, 55.01, 0.67, 0.01)\n",
        "\n",
        "# Add a submit button\n",
        "if st.button(\"Submit\"):\n",
        "    # Create input DataFrame\n",
        "    input_data = pd.DataFrame({\n",
        "        'Token_0': [TP],\n",
        "        'Token_1': [temp],\n",
        "        'Token_2': [time],\n",
        "        'Token_3': [PS],\n",
        "        'Token_4': [BET],\n",
        "        'Token_5': [PV],\n",
        "        'Token_6': [carbon],\n",
        "        'Token_7': [hydrogen],\n",
        "        'Token_8': [nitrogen],\n",
        "        'Token_9': [oxygen]\n",
        "    })\n",
        "\n",
        "    # One-hot encode the input data\n",
        "    input_encoded = pd.get_dummies(input_data)\n",
        "\n",
        "    # Align input_encoded with the required columns from training\n",
        "    for col in required_columns:\n",
        "        if col not in input_encoded.columns:\n",
        "            input_encoded[col] = 0\n",
        "    input_encoded = input_encoded[required_columns]\n",
        "\n",
        "    # Make the prediction\n",
        "    prediction = model.predict(input_encoded)[0]\n",
        "\n",
        "    # Display the prediction\n",
        "    st.subheader(f\"Qm (mg/g): {prediction}\")"
      ],
      "metadata": {
        "id": "sKjSRz9OXQRr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}